{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "from torch.utils.data import DataLoader,SequentialSampler,RandomSampler,TensorDataset,random_split\n",
    "from tqdm.notebook import tqdm\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header = None)\n",
    "df.columns=['Sentiment', 'id', 'Date', 'Query', 'User', 'Tweet']\n",
    "df = df.drop(columns=['id', 'Date', 'Query', 'User'], axis=1)\n",
    "df.head()\n",
    "df['Sentiment'] = df.Sentiment.replace(4,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\n",
    "mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\n",
    "urls = re.compile(r\"https?://\\S+\")\n",
    "\n",
    "def process_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = hashtags.sub(' hashtag', text)\n",
    "    text = mentions.sub(' entity', text)\n",
    "    return text.strip().lower()\n",
    "df['Tweet'] = df.Tweet.apply(process_text)\n",
    "df.head()\n",
    "df_1000 = pd.concat([df[df['Sentiment'] == 0].head(5000), df[df['Sentiment'] == 1].head(5000)])\n",
    "df = df_1000\n",
    "labels = df.Sentiment.values\n",
    "text = df.Tweet.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertForSequenceClassification,AdamW\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case = True)\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "for i in text:\n",
    "    encoded_data = tokenizer.encode_plus(\n",
    "    i,\n",
    "    add_special_tokens=True,\n",
    "    max_length=64,\n",
    "    pad_to_max_length = True,\n",
    "    return_attention_mask= True,\n",
    "    return_tensors='pt')\n",
    "    input_ids.append(encoded_data['input_ids'])\n",
    "    attention_mask.append(encoded_data['attention_mask'])\n",
    "input_ids = torch.cat(input_ids,dim=0)\n",
    "attention_mask = torch.cat(attention_mask,dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "dataset = TensorDataset(input_ids,attention_mask,labels)\n",
    "train_size = int(0.8*len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset,val_dataset = random_split(dataset,[train_size,val_size])\n",
    "\n",
    "print('Training Size - ',train_size)\n",
    "print('Validation Size - ',val_size)\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_dataset,sampler = RandomSampler(train_dataset),\n",
    "                     batch_size = 32)\n",
    "val_dl = DataLoader(val_dataset,sampler = SequentialSampler(val_dataset),\n",
    "                     batch_size = 32)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "'bert-base-uncased',\n",
    "num_labels = 2,\n",
    "output_attentions = False,\n",
    "output_hidden_states = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting seed and checking for gpu cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),lr = 2e-5,eps=1e-8)\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 1\n",
    "total_steps = len(train_dl)*epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,\n",
    "                                           num_training_steps=total_steps)\n",
    "def accuracy(preds,labels):\n",
    "    pred_flat = np.argmax(preds,axis=1).flatten()\n",
    "    label_flat = labels.flatten()\n",
    "    return np.sum(pred_flat==label_flat)/len(label_flat)\n",
    "\n",
    "def evaluate(dataloader_test):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions,true_vals = [],[]\n",
    "    for batch in dataloader_test:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids':batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    loss_val_avg = loss_val_total / len(dataloader_test)\n",
    "    predictions = np.concatenate(predictions,axis=0)\n",
    "    true_vals = np.concatenate(true_vals,axis=0)\n",
    "    return loss_val_avg,predictions,true_vals\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(train_dl, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(train_dl)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(val_dl)\n",
    "    val_acc = accuracy(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'Accuracy: {val_acc}')\n",
    "    \n",
    "output_dir = './'\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "from transformers import BertTokenizer,BertForSequenceClassification\n",
    "import torch\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "output_dir = './'\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)\n",
    "\n",
    "def Sentiment(sent):\n",
    "    output_dir = './'\n",
    "    tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "    model_loaded = BertForSequenceClassification.from_pretrained(output_dir)\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent, \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "        \n",
    "    input_id = encoded_dict['input_ids']\n",
    "\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "    input_id = torch.LongTensor(input_id)\n",
    "    attention_mask = torch.LongTensor(attention_mask)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_loaded = model_loaded.to(device)\n",
    "    input_id = input_id.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    index = logits.argmax()\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_name = \"nn10000\"\n",
    "pickle.dump(model, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and getting the sentiment value as a column in the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = pickle.load(open('nn10000', 'rb'))\n",
    "path = 'tweets/tweets_preprocessed.csv'\n",
    "df = pd.read_csv(path)\n",
    "text_in_string = []\n",
    "a = df['processed_text'].tolist()\n",
    "import ast\n",
    "for sent in a:\n",
    "    b = ast.literal_eval(sent)\n",
    "    str1 = ' '.join(b)\n",
    "    text_in_string.append(str1)\n",
    "    \n",
    "    \n",
    "setiment_array = []\n",
    "for sentence in text_in_string:\n",
    "    setiment_array.append(Sentiment(sentence))\n",
    "df['sentiment'] = setiment_array\n",
    "df.to_csv('positive_processed-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code referenced from https://www.kaggle.com/aquib5559/1-6million-tweet-sentiment-analysis-using-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
